{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv('ml-20m/genome-tags.csv')\n",
    "scores = pd.read_csv('ml-20m/genome-scores.csv')\n",
    "movies = pd.read_csv('ml-20m/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('Hybrid/feature_extraction/Genome/movie_genomes.npy')\n",
    "A = np.load('ml-20m/movie_genomes.npy', allow_pickle=True)\n",
    "Asortedidx = (-A).argsort(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_thres = 3.5\n",
    "user_ratings = pd.read_csv('ml-20m/ratings.csv')\n",
    "user_ratings_above_thres = user_ratings[user_ratings['rating'] > rating_thres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     userId  movieId  rating   timestamp\n",
       "6         1      151     4.0  1094785734\n",
       "7         1      223     4.0  1112485573\n",
       "8         1      253     4.0  1112484940\n",
       "9         1      260     4.0  1112484826\n",
       "10        1      293     4.0  1112484703\n",
       "..      ...      ...     ...         ...\n",
       "184       2      541     5.0   974821014\n",
       "185       2      589     5.0   974820658\n",
       "187       2      908     4.0   974820691\n",
       "188       2      924     5.0   974821014\n",
       "190       2     1196     5.0   974821014\n",
       "\n",
       "[100 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>151</td>\n      <td>4.0</td>\n      <td>1094785734</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>223</td>\n      <td>4.0</td>\n      <td>1112485573</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>253</td>\n      <td>4.0</td>\n      <td>1112484940</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>260</td>\n      <td>4.0</td>\n      <td>1112484826</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>293</td>\n      <td>4.0</td>\n      <td>1112484703</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>2</td>\n      <td>541</td>\n      <td>5.0</td>\n      <td>974821014</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>2</td>\n      <td>589</td>\n      <td>5.0</td>\n      <td>974820658</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>2</td>\n      <td>908</td>\n      <td>4.0</td>\n      <td>974820691</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>2</td>\n      <td>924</td>\n      <td>5.0</td>\n      <td>974821014</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>2</td>\n      <td>1196</td>\n      <td>5.0</td>\n      <td>974821014</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "user_ratings_above_thres[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_dict = {}\n",
    "# max_user_id = user_ratings.userId.max()\n",
    "max_user_id = min(user_ratings_above_thres.userId.max(), 150000)\n",
    "num_items_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "138287"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(list(set(user_ratings_above_thres.userId.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in range(max_user_id):\n",
    "    # if uid not in user_movie_dict.keys() :\n",
    "    rating_list = user_ratings_above_thres[ user_ratings_above_thres['userId'] == uid ]\n",
    "    num_items_list.append(len(rating_list))\n",
    "    user_movie_dict[uid] = rating_list\n",
    "    \n",
    "np.save('rating_dict.npy', user_movie_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_dict = np.load('rating_dict.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "207\n"
     ]
    }
   ],
   "source": [
    "empty_keys = []\n",
    "for key in user_movie_dict:\n",
    "    if len(user_movie_dict[key]) == 0:\n",
    "        empty_keys.append(key)\n",
    "\n",
    "print(len(empty_keys))\n",
    "for key in empty_keys:\n",
    "    del user_movie_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[151, 223, 253, 260, 293, 296, 318, 541, 1036, 1079, 1090, 1097, 1196, 1198, 1200, 1214, 1215, 1219, 1240, 1249, 1258, 1259, 1266, 1278, 1321, 1333, 1358, 1374, 1387, 1967, 2021, 2100, 2118, 2138, 2140, 2143, 2173, 2174, 2193, 2288, 2291, 2542, 2628, 2762, 2872, 2944, 2959, 2968, 3081, 3153, 3479, 3489, 3499, 3889, 3996, 4011, 4027, 4128, 4306, 4467, 4571, 4754, 4896, 4911, 4993, 5026, 5039, 5171, 5540, 5797, 5816, 5952, 6093, 6333, 6539, 6754, 6774, 7046, 7153, 7389, 7438, 7454, 7757, 8368, 8507, 8636, 8961, 31696]\n"
     ]
    }
   ],
   "source": [
    "print(user_movie_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = user_movie_dict.keys()\n",
    "movie_ids = list(set(user_ratings.movieId.tolist()))\n",
    "movie_ids.insert(0, 0)   # Insert padding item\n",
    "# movie_ids = [0, *movie_ids]\n",
    "\n",
    "movie_ids_to_idx = {}\n",
    "for i, mid in enumerate(movie_ids):\n",
    "    movie_ids_to_idx[mid] = i\n",
    "user_idxs = np.arange(len(user_ids))\n",
    "\n",
    "num_movies = []\n",
    "for key in user_movie_dict:\n",
    "    num_movies.append(len(user_movie_dict[key]))\n",
    "\n",
    "num_total_movies = len(movie_ids)\n",
    "\n",
    "# Convert original movie idx into \n",
    "for uid in user_movie_dict:\n",
    "    for idx in range(len(user_movie_dict[uid])):\n",
    "        user_movie_dict[uid][idx] = movie_ids_to_idx[user_movie_dict[uid][idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[152, 223, 253, 260, 293, 296, 318, 540, 1020, 1060, 1071, 1078, 1174, 1176, 1178, 1191, 1192, 1196, 1215, 1224, 1233, 1234, 1241, 1253, 1295, 1307, 1331, 1346, 1359, 1886, 1940, 2019, 2037, 2057, 2059, 2062, 2092, 2093, 2112, 2206, 2209, 2460, 2546, 2679, 2789, 2861, 2876, 2885, 2997, 3069, 3393, 3402, 3412, 3799, 3905, 3920, 3936, 4037, 4215, 4376, 4480, 4662, 4804, 4819, 4901, 4934, 4947, 5079, 5447, 5702, 5721, 5857, 5998, 6238, 6433, 6648, 6668, 6938, 7045, 7281, 7316, 7332, 7459, 7773, 7864, 7957, 8282, 9821]\n"
     ]
    }
   ],
   "source": [
    "print(user_movie_dict[1])"
   ]
  },
  {
   "source": [
    "## Statistics\n",
    "- num. of total users : 138,286\n",
    "- num. of movies per users : 72.27 +- 102.24 (max=3177, min=1)\n",
    "- num. of unique movies : \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list(input_list, padded_len=128):\n",
    "    padding = []\n",
    "    input_list = list(input_list)\n",
    "    if len(input_list) < padded_len:\n",
    "        padding = [0] * (padded_len - len(input_list))\n",
    "    output_list = input_list + padding\n",
    "    output_list = output_list[:padded_len]\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_masked_binary_vector(input_list, mask_list):    \n",
    "    bin_vector = np.zeros(num_total_movies, dtype=float)\n",
    "    bin_vector[np.array(input_list, dtype=int)] = 1.\n",
    "    bin_vector[mask_list] = 0.\n",
    "    return bin_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import TransformerModel\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_batch(batch_size=20, input_size=35):\n",
    "    # choose num_users\n",
    "    user_idx = np.random.choice(user_idxs, batch_size)\n",
    "    np.random.shuffle(user_idx)\n",
    "    sources = []\n",
    "    targets = []\n",
    "    \n",
    "    # choose movie_seen and movie_to_be_seen (padding if input_size > num_movie_seen)\n",
    "    for uid in user_idx:\n",
    "        # original_bivec = generate_masked_binary_vector(user_movie_dict[uid], [])\n",
    "\n",
    "        source_mask_idx = np.random.choice(np.arange(num_total_movies), num_total_movies//2, replace=False)\n",
    "        target_mask_idx = np.arange(num_total_movies)[~np.isin(np.arange(num_total_movies), source_mask_idx)]\n",
    "\n",
    "        source_bivec = generate_masked_binary_vector(user_movie_dict[uid], source_mask_idx)\n",
    "        target_bivec = generate_masked_binary_vector(user_movie_dict[uid], target_mask_idx)\n",
    "        \n",
    "        source = source_bivec.nonzero()[0]\n",
    "        source = pad_list(list(source))\n",
    "        source = np.array(source)\n",
    "        \n",
    "        sources.append(source)\n",
    "        targets.append(target_bivec)\n",
    "\n",
    "    sources = torch.Tensor(sources).to(device)\n",
    "    targets = torch.Tensor(targets).to(device)\n",
    "\n",
    "    return sources, targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([20, 26745])"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([20, 128])"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitems = num_total_movies\n",
    "emsize = 200\n",
    "nhid = 200\n",
    "nlayers = 2\n",
    "nhead = 2\n",
    "dropout = 0.2\n",
    "input_size = 35\n",
    "model = TransformerModel(nitems, emsize, nhead, nhid, nlayers, dropout, use_posenc=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "lr = 5.0 # 학습률\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "import time\n",
    "def train():\n",
    "    model.train() # 학습 모드를 시작합니다.\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(TEXT.vocab.stoi)\n",
    "    for batch, i in enumerate(range(0, input_size - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # 평가 모드를 시작합니다.\n",
    "    total_loss = 0.\n",
    "    ntokens = len(TEXT.vocab.stoi)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output = eval_model(data)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  }
 ]
}